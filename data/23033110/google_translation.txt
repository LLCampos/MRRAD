ABSTRACT BACKGROUND: The default standardization of images used in medicine was conducted in 1993 through the DICOM (Digital Imaging and Communications in Medicine). Several tests using this standard and are increasingly required software able to handle this kind of image, but such software usually do not have the free and open source format, and this hampers their adjustment to the most different interests. To develop and validate a free software and open source able to manipulate DICOM images of coronary CT angiography exams. METHODS: We developed and tested software titled ImageLab the evaluation tests of 100 randomly selected using a database. They carried out 600 tests divided by two observers using ImageLab and other software marketed to the CT scanners Philips Brilliance in assessing the presence of coronary lesions and plaques in the territories trunk of Left Coronary (TCE) and Artery Anterior Descending ( ADA). To evaluate intraobserver, interobserver and intersoftware concordances, use simple statistical agreement Kappa. RESULTS: The concordance observed between the software were generally classified as substantial or almost perfect in most comparisons. CONCLUSION: ImageLab software agreed with the Philips software evaluation of CT angiography scans of coronary especially in patients without lesions, with less than 50% lesions in TBI and less than 70% in the ADA. The agreement to injury > 70% in the ADA was lower, but it is also observed when using the standard anatomical reference. Keywords: Diagnostic imaging; computed tomography; coronary vessels; Validation of computer programs.     Introduction In medical uses into a specific image pattern called DICOM (Digital Imaging and Communications in Medicine). This standard was developed to facilitate communication between the software and hardware related to this process. The DICOM format, padronizado1 in 1993 by the Congress RSNA (Radiological Society of North America), aimed at the standardization of the rules that medical information is transmitted and armazenadas2-4. The visualization and processing of medical images are realized through specific software. Many of these resources are not available for free or are sold with the equipment, but it is not common to find free software and open source for this image format. The public domain of a medical software technology could reduce costs, standardize the multi use, allow continuous development and facilitate the development of several lines of research, and some believe that this format could contribute to the reduction of social differences between countries5. The National Institute of Science and Technology in Medicine Assisted by Scientific Computing (INCT-MACC) involves 33 national institutions in 11 states, totaling 128 researchers. One of the research areas of the INCT-MACC is the medical image processing, which will allow the acquisition of information to improve the computational modeling of the human cardiovascular system, also being developed by INCT-MACC. For this purpose it designed a free and open-source software called ImageLab. This software would have features of being friendly with the user requiring better assessment. The aim of the study was to develop and evaluate the reliability, compliance and reproducibility of the new software over another in current use in coronary angiography equipment.   Methods In joint work of the Federal University of Rio de Janeiro (UFRJ) with the National Laboratory for Scientific Computing (LNCC), we developed a software for DICOM image analysis. This free open source software called ImageLab and has created tools for analysis and processing of coronary CT angiography images. From a population of 6,216 patients who underwent coronary angiography examination of between May 2005 and December 2010, we applied the inclusion criteria, ie, patients with complete data recorded in the database created in 2008 and selected 2,895 patients. Later after applying the exclusion criteria, the presence of stents in the left main coronary artery or anterior descending artery (ADA), surgical clip, due to coronary artery bypass surgery and patients who did not have images stored on served, 534 cases were selected (Figure 1). The site randon.org perform random selection withdrawing 120 of 534 patients, and use the first 100 cases. All patients had their identifying data replaced with consecutive numbers, by people not involved in the analysis of the images becoming blind. the raw data of coronary angiography images, obtained using CTs available in the service (GE lightspeed VTC 64 and 32, Philips Brilliance 64, 40 and 16) were used. All pictures followed standard protocol acquisition using similar techniques. All 100 tests were analyzed by two software. The Philips Brilliance software, purchased along with cardiovascular package (available Worsktation own for DICOM type image analysis). And ImageLab software developed in this project, installed on the same Worsktation (to neutralize the possible variation of processing power if they were installed on computers with different capacity). We chose the left main coronary artery and the ADA clinical significance and to facilitate the analysis, since the use of the 16 segments in their entirety would result in a large number of variables. We followed the nomenclature proposed by AHA relating to segments 5, 6, 7 and 86. The evaluation of the presence of coronary lesions larger or smaller than 50% was used for the segment 5 (left main coronary artery) and the other segments (LAD) use 70% cuts. Additional form variables were also recorded: the presence of atherosclerotic type calcified plaques, not calcified and partially calcified (in each segment); subjective quality images; Image analysis time (recorded by observer 1). Image analysis was done by viewing orthogonal planes selected from the image block in three dimensional space, starting from the analysis transverse plane of the chest towards the head to the feet in order to visualize the aortic artery, the trunk origin left coronary artery and the ADA. The ratings for the degree of stenosis follow the pattern analysis where the filling failure by the contrasted vessel defines the presence of injury. The analysis of the type of board responsible for the damage was done subjectively. Characterization of plaques were carried out according to their morphology and signal intensity, following the traditional scale used in CT scans, the range of Hounsfield (HU) 7. The plates were classified as calcified (tissue adjacent to the vessel with more signal strength that the vessel contrasted - Signal > 130 HU); Noncalcified (tissue adjacent to the vessel with less signal the vessel contrasted - Sign < -50 HU); and partly calcified (heterogeneous content). The two feature software tool for location and analysis of any point in three dimensional space. This tool was used to assess the vessel, in its axial plane (view from within the vessel) in all their extension, and when there is the presence of plaques and coronary lesions, all the orthogonal planes may be used simultaneously in exact topography that these findings may be. Analysis of Images Two observers with experience above five years, equivalent to level 3 competence clínica8, used commercial software Philips and ImageLab, installed on the same computer, to analyze the ADA segment according to the variables described in Table 1. To avoid measurement bias, the analysis of the software occurred at intervals longer than 15 days. A total of 600 analyzes were performed to evaluate the intraobserver, interobserver and intersoftware concordances. Statistical Analysis Descriptive Analysis as numeric variables in the form of mean +/- standard deviation. Categorical variables as number (n) and percentages (%). Kappa statistics to calculate the interobserver and intraobserver reproducibility, all with 95% confidence interval and simple agreement to measure cases with small numbers of disagreement. The software used was R for Linux. Use Table 1 to evaluate the degree of agreement between the concordâncias9.   Results After random selection of 120 cases, 7 cases numbering less than 100 were excluded due to lack of contrast examination stage (examination of the calcium score mode without CT angiography of coronary heart). A total of 100 scans with number from 1 to 107 were included for the analyzes 600 divided by the observers and software. (All results of matches obtained with R for Linux program can be accessed by the link http://cl.ly/3c193E0J1o1M0f360u1d) The result of the release of ImageLab software used in this project has become appropriate with visual and convenient usability (Figure 2). All 100 patients studied underwent the tests between July 2009 and November 2010, the majority were male (65) and the average age of 58 years (23-85). The average body mass index was 27 kg / m2, ranking the average population overweight (25% classified as obese). Only 15% of the population did not have any risk factor, and 35% were asymptomatic (Table. 2). The most frequent symptom observed was the presence of atypical pain for Coronary Artery Disease (CAD), and most of the tests was to evaluate indications of any symptoms. It is noteworthy that 36% of patients were referred because of the presence of altered functional test, and 16% for risk stratification (routine assessment unrelated symptoms or abnormal tests); only 2% to exclude the diagnosis of atherothrombotic disease as etiology of cardiomyopathy; and 2% in the preoperative evaluation (evaluation of cardiovascular surgical risk). The observer 1 used an electronic device clipboard format (tablet Apple® - Ipad 64Gb Wifi) to record the analysis by Bento® software for Ipad. This allowed registering the time of simple analysis (Table 3). The total time of the analysis performed by the observer 1 was approximately 6.8 hours, distributed in 14 days. The average time spent in each test was 2 minutes and 4 seconds (21 to 612/2). The average time spent with ImageLab software for the analysis of all patients was 226.2 minutes, while with the Philips Brilliance software was 180.9 (20% less). The second analysis by both software was faster with the decrease in total time at 11.9 minutes and 10.7 minutes for the software and ImageLab Philips Brilliance respectively. The subjective quality of recorded images by score 1 to 3; 1 low quality, 2 intermediate quality, and 3 high quality. Twenty-four percent of the images were classified as low quality; 64.2% as intermediate; and 11.8%, as high quality (76% with intermediate or high quality). To evaluate the intraobserver and interobserver concordance, we use the simple agreement (sum of concordant findings due to the total number of cases), in the presence of little or no discordant case (heterogeneous distribution in the 2 x 2 table with few or no cases in one of the houses ), and using kappa statistics (Table 1) as a reference to the degree of agreement between the results8. The average of the observations of the 600 analyzes (Table 3) demonstrated no lesion in the left main coronary artery in 82%, and 49.3% in ADA. Less than 1% with lesions > 50% in the left main coronary artery and 9% with lesions > 70% in some segment of the ADA. The type most commonly observed board was calcified. It was possible to carry out the correlation analysis by Kappa for all types of comparison (intraobserver, interobserver and intersoftware), the variables: absence of injury and injury < 50% of the left main coronary artery; absence of injury to the ADA and lesion > 70% in the middle third of this artery (Table 4). In the evaluation of the plates Kappa can be realized only with calcified plaque variable in the left main coronary artery (Table 5). The other agreements were made by the measure of simple agreement. In order to evaluate the intraobserver agreement compare the analyzes performed by the viewer 1 with ImageLab software at time 1 and ImageLab at time 2, as well as the Philips Brilliance software at time 1 and Philips Brilliance in time 2 All ratings measured by Kappa or by simple agreement in the left main coronary artery were more than 60. Only the variable lesions > 70% in the middle third of the descending artery, the interobserver evaluation by Philips Brilliance software, showed moderate agreement (49.7 to 13.8 to 85.6), all too concordances observed in the previous ADA were higher 609. The evaluation absence of lesions and lesion < 50% in the left main coronary artery, as well as the assessment of lesion > 70% in the middle third of the ADA showed greater intraobserver agreement for the software Philips Brilliance, the other remained similar. The intersoftware analysis showed greater concordance to 80 for all measurements performed by Kappa, except for injury assessment > 70% in the middle third of ADA (79.6 to 63.6 to 95.7), while all single intersoftware agreements were greater than 80. When analyzed the most frequent observations and greater clinical significance (Table 6), it was possible to use the Kappa, which showed higher agreement for the injury absence of identification (kappa greater than 90 for all comparisons) and then the nameplates calcified also presented a substantial degree of agreement. The correlation decreases assess significant lesions in ADA ( > 70%) in the worst kappa was 47.8 for the inter review and ImageLab software.   Discussion Our study used patients referred by their doctors, for various clinical indications for the coronary angiography. These patients found on the day of the particular services directed to this type of examination usually have a low probability to disease of middle and use the high negative predictive value of exame10 to exclude the diagnosis. We note that in the study population, only 9% had typical chest pain for CAD, and when evaluating the results of the calcium scores of that population (not used in the assessments), only 20% were valued above the 75th percentile for age and sex, which is associated with increased cardiovascular risk for global eventos11. The use of patients referred for indications of cardiological practice allows the viability of this project, but can pose a problem. The lack of all types of injury and plates by coronary segments is certainly a limitation to the analysis of concordances. In these cases it was possible only perform simple agreement because the Kappa needs a more varied distribution of findings to be calculated. One way to fix this problem would be the inclusion of patients distributed by injuries and cards, in order to force the varied input all kinds of findings. This approach would change the profile of the population being studied that would certainly be different from the population found on a daily basis, sent by doctors to clarify a diagnostic doubt. The evaluation of only one part of the examination (phase contrast) without clinical data of patients, possibly decreases the capacity of observers in the interpretation of images. This may interfere with test report and perhaps even in medical management, but our goal was not to assess how the new software is accurate in relation to the reference standard (coronary angiography), but compare it with other widely used software. We have not found in our review specific scientific validation for the Philips software, but we believe that daily use in clinical practice and scientific work allows us to conclude that there is some kind of validation for this software. This work was motivated by the line of research funded by Faperj computer modeling of the cardiovascular system. Its future objective use ImageLab in coronary CT angiography exams in DICOM format and possibly other exams in this format. Subjective assessment of the injury, a representative picture of the artery that is constantly moving and is generally less than 3 mm can be difficult. Moreover, the display of a complex structure in three-dimensional space expressed in two dimensions an image is challenging accuracy. The estimated degree of injury with these limitations will define the clinical approach to be taken in several cases. Despite the lower accuracy compared with angiography cine (CA) in coronary angiography can analyze the image in four dimensions (three dimensions over time of a cardiac cycle) and it possibly facilitates compliance with the CA, which is reflected in a high sensitivity and specificity for coronary angiography with values ​​greater than 90% 9. We got a good agreement in most of the analyzes and the direct evaluation of the software. This agreement was higher in intraobserver evaluation, which was expected. Another predictable given was greater agreement in the case of absence of injury. Rated the worst occurred among observers with ImageLab software in injury analysis > 70% in ADA (Kappa 47.8). This discrepancy could be explained in part by the difficult to quantify subjective in some cases and the different interpretations of where the injury is located, that is, even when there was a correct assessment of a particular injury, this information was not recorded correctly if it occurs in different segments (lesions > 70% in ADA at the intersection of the proximal and middle segment, now being interpreted in the previous segment, now interpreted as being in the middle segment). Despite the limitation of the study population described above, the simple concordance performed in cases with few observations of injury and plates were always very good. The lack of this information may prejudice the external validity of the software for more rare finds, but the vast majority of patients who are referred for this exam does not see these changes. In the analysis of concordances with greater clinical significance and more frequent observations (Table 6) also observed greater agreement on the observation absence of lesions in ADA, with Kappa always above 90. In this same table is observed lower agreement for lesion > 70% and the identification of calcified plaques. These data are consistent with the characteristics of coronary angiography, the use of which is more suitable to rule out lesions and plaques, ie the method is more accurate and is more reliable when it is observed coronary changes. When we look in the literature evaluating the agreements with CAT, despite the use of anatomical reference standard, there is wide variation, with Kappa between 36-63 for detailed dichotomous measures the degree of injury (0 1 - 50.51 to 69 and > 70) and Kappa 37-82 for less detailed dichotomous measures ( < 70 or > 70) 12. Another interesting data using two observers is the change in interpretation of a previous report of a CAT when compared to a recent evaluation, with moderate agreement and Kappa ranging between 54 and 60 among observers. This occurs even when the recent agreement between these observers is good (Kappa 69) 13. These data can be related to the information available by the observer of the images during the time of analysis (images associated with clinical history, the context of the examination, previous tests and symptoms) compared with the analysis of images without prior information about the patients. In our study, the lack of information about the patient, including their identification, characteristics of pain, chest, results of functional tests and evaluation of the calcium score, may have influenced the interpretation of the images, but our goal was not to release a clinical report, but the comparison between software.   Conclusion We see very good agreement between the two software, both intraobserver assessment regarding the interobserver evaluation. The evaluation of intersoftwares concordance in lesions and plaques analysis in general is higher than 80. The ImageLab software agrees with the Philips software in the evaluation of coronary CT angiography exams, has great potential in helping clinical practice and research in this area, despite the need for a more robust evaluation. It can be used as a tool in the computer modeling of the cardiovascular system search line and possibly other areas related images in DICOM format. Potential Conflict of Interest No potential conflict of interest relevant. Sources of Funding This study had no external funding sources. Study Association This article is part of Master's thesis Marcelo Souza Hadlich the Federal University of Rio de Janeiro.   